{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laurindocak/Calculo_Metricas/blob/main/YOLOv8_cachorro_gato.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b583bc1",
      "metadata": {
        "id": "8b583bc1"
      },
      "source": [
        "\n",
        "# YOLOv8 ‚Äî Treino com **cachorro** e **gato** (Transfer Learning, Colab)\n",
        "Notebook completo para:\n",
        "1. Preparar dataset no formato YOLO (imagens e r√≥tulos).\n",
        "2. (Opcional) Converter **LabelMe JSON ‚Üí YOLO**.\n",
        "3. Treinar, avaliar e fazer infer√™ncia usando **Ultralytics YOLOv8**.\n",
        "4. Exportar pesos e resultados.\n",
        "\n",
        "> **Classes definidas:** `cachorro`, `gato`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ecfdaac2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecfdaac2",
        "outputId": "a26e7d3f-ae6f-48a3-927e-5f48a637c135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics importado com sucesso.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@title Instalar depend√™ncias (Ultralytics) { display-mode: \"form\" }\n",
        "# Se estiver no Colab, a linha abaixo far√° a instala√ß√£o.\n",
        "!pip -q install ultralytics>=8.2.0\n",
        "from ultralytics import YOLO\n",
        "print(\"Ultralytics importado com sucesso.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b13d8aaa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b13d8aaa",
        "outputId": "21545f8b-2fa6-4bbb-a1dc-a090ecd9b6d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@title Conectar ao Google Drive (Colab) { display-mode: \"form\" }\n",
        "# Execute esta c√©lula no Google Colab para montar o Drive. Se estiver em ambiente local, pode ignorar.\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount('/content/drive')\n",
        "    IN_COLAB = True\n",
        "except Exception as e:\n",
        "    print(\"Parece que n√£o estamos no Colab ou o Drive n√£o foi montado:\", e)\n",
        "    IN_COLAB = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fd251309",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd251309",
        "outputId": "066fe0cb-501a-4361-c561-b1c1ac6dfbca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estrutura criada em: /content/drive/MyDrive/YOLO_cachorro_gato\n",
            "- /content/drive/MyDrive/YOLO_cachorro_gato/datasets/cachorro_gato\n",
            "- /content/drive/MyDrive/YOLO_cachorro_gato/datasets/cachorro_gato/images/train\n",
            "- /content/drive/MyDrive/YOLO_cachorro_gato/datasets/cachorro_gato/images/val\n",
            "- /content/drive/MyDrive/YOLO_cachorro_gato/datasets/cachorro_gato/images/test\n",
            "- /content/drive/MyDrive/YOLO_cachorro_gato/datasets/cachorro_gato/labels/train\n",
            "- /content/drive/MyDrive/YOLO_cachorro_gato/datasets/cachorro_gato/labels/val\n",
            "- /content/drive/MyDrive/YOLO_cachorro_gato/datasets/cachorro_gato/labels/test\n",
            "\n",
            "Arquivo data.yaml salvo em: /content/drive/MyDrive/YOLO_cachorro_gato/datasets/cachorro_gato/data.yaml\n",
            "Conte√∫do:\n",
            "path: /content/drive/MyDrive/YOLO_cachorro_gato/datasets/cachorro_gato\n",
            "train: images/train\n",
            "val: images/val\n",
            "test: images/test\n",
            "names:\n",
            "- cachorro\n",
            "- gato\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@title Definir caminhos do projeto e criar estrutura { display-mode: \"form\" }\n",
        "from pathlib import Path\n",
        "import os, textwrap, yaml\n",
        "\n",
        "# Altere se desejar outro caminho dentro do Drive\n",
        "BASE_DIR = Path('/content/drive/MyDrive/YOLO_cachorro_gato') if 'IN_COLAB' in globals() and IN_COLAB else Path('/content/YOLO_cachorro_gato')\n",
        "DATASET_DIR = BASE_DIR / 'datasets' / 'cachorro_gato'\n",
        "IMAGES_TRAIN = DATASET_DIR / 'images' / 'train'\n",
        "IMAGES_VAL   = DATASET_DIR / 'images' / 'val'\n",
        "IMAGES_TEST  = DATASET_DIR / 'images' / 'test'\n",
        "LABELS_TRAIN = DATASET_DIR / 'labels' / 'train'\n",
        "LABELS_VAL   = DATASET_DIR / 'labels' / 'val'\n",
        "LABELS_TEST  = DATASET_DIR / 'labels' / 'test'\n",
        "RESULTS_DIR  = BASE_DIR / 'results'\n",
        "\n",
        "for p in [IMAGES_TRAIN, IMAGES_VAL, IMAGES_TEST, LABELS_TRAIN, LABELS_VAL, LABELS_TEST, RESULTS_DIR]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Estrutura criada em:\", BASE_DIR)\n",
        "for p in [DATASET_DIR, IMAGES_TRAIN, IMAGES_VAL, IMAGES_TEST, LABELS_TRAIN, LABELS_VAL, LABELS_TEST]:\n",
        "    print(\"-\", p)\n",
        "\n",
        "# Gerar data.yaml automaticamente\n",
        "data_yaml = {\n",
        "    'path': str(DATASET_DIR),\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'test': 'images/test',\n",
        "    'names': ['cachorro', 'gato']\n",
        "}\n",
        "with open(DATASET_DIR / 'data.yaml', 'w') as f:\n",
        "    yaml.safe_dump(data_yaml, f, sort_keys=False, allow_unicode=True)\n",
        "\n",
        "print(\"\\nArquivo data.yaml salvo em:\", DATASET_DIR / 'data.yaml')\n",
        "print(\"Conte√∫do:\")\n",
        "print(yaml.safe_dump(data_yaml, sort_keys=False, allow_unicode=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "528752ba",
      "metadata": {
        "id": "528752ba"
      },
      "source": [
        "\n",
        "## üì• Como colocar as imagens e r√≥tulos\n",
        "- Coloque suas imagens `.jpg/.png` dentro de:\n",
        "  - `datasets/cachorro_gato/images/train`\n",
        "  - `datasets/cachorro_gato/images/val`\n",
        "  - `datasets/cachorro_gato/images/test` *(opcional)*\n",
        "- Os r√≥tulos YOLO `.txt` correspondentes devem ir em:\n",
        "  - `datasets/cachorro_gato/labels/train`\n",
        "  - `datasets/cachorro_gato/labels/val`\n",
        "  - `datasets/cachorro_gato/labels/test` *(opcional)*\n",
        "\n",
        "> **Formato YOLO por linha**: `class_id x_center y_center width height` (valores normalizados entre 0 e 1).\n",
        ">\n",
        "> **IDs de classe** neste projeto: `0 = cachorro`, `1 = gato`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2537b13",
      "metadata": {
        "id": "f2537b13"
      },
      "source": [
        "\n",
        "## üîÅ (Opcional) Converter r√≥tulos do **LabelMe JSON** para YOLO\n",
        "- Coloque seus arquivos `.json` do LabelMe e as imagens correspondentes numa pasta tempor√°ria.\n",
        "- A c√©lula abaixo converte cada JSON para um `.txt` no formato YOLO e salva em `labels/train` (ou `labels/val` conforme ajustar).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "97c4aee6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97c4aee6",
        "outputId": "98583c77-abe6-4a15-91b6-1cded3049703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pronto. Ajuste as vari√°veis e descomente a chamada para converter.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@title Conversor LabelMe JSON ‚Üí YOLO (caixas) { display-mode: \"form\" }\n",
        "import json, shutil\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "def bbox_from_shape(shape):\n",
        "    # Suporta shapes tipo rectangle ou polygon (usa bounding box do pol√≠gono)\n",
        "    if shape.get('shape_type', 'polygon') == 'rectangle':\n",
        "        # rectangle: points = [[x1, y1], [x2, y2]]\n",
        "        (x1, y1), (x2, y2) = shape['points']\n",
        "        xmin, ymin = min(x1, x2), min(y1, y2)\n",
        "        xmax, ymax = max(x1, x2), max(y1, y2)\n",
        "    else:\n",
        "        xs = [p[0] for p in shape['points']]\n",
        "        ys = [p[1] for p in shape['points']]\n",
        "        xmin, xmax = min(xs), max(xs)\n",
        "        ymin, ymax = min(ys), max(ys)\n",
        "    return xmin, ymin, xmax, ymax\n",
        "\n",
        "def convert_labelme_folder_to_yolo(json_folder, images_out_dir, labels_out_dir, class_map):\n",
        "    json_folder = Path(json_folder)\n",
        "    images_out  = Path(images_out_dir); images_out.mkdir(parents=True, exist_ok=True)\n",
        "    labels_out  = Path(labels_out_dir); labels_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for json_path in json_folder.glob(\"*.json\"):\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        image_path = json_folder / data['imagePath']\n",
        "        if not image_path.exists():\n",
        "            # tenta localizar a imagem por nome na pasta\n",
        "            possible = list(json_folder.glob(Path(data['imagePath']).name))\n",
        "            if possible:\n",
        "                image_path = possible[0]\n",
        "            else:\n",
        "                print(f\"[AVISO] Imagem n√£o encontrada para {json_path.name}\")\n",
        "                continue\n",
        "\n",
        "        # abre imagem para pegar dimens√µes\n",
        "        with Image.open(image_path) as img:\n",
        "            w, h = img.size\n",
        "\n",
        "        # copia imagem para pasta de destino\n",
        "        dest_img = images_out / image_path.name\n",
        "        if not dest_img.exists():\n",
        "            shutil.copy2(image_path, dest_img)\n",
        "\n",
        "        # cria label .txt\n",
        "        label_path = labels_out / (image_path.stem + \".txt\")\n",
        "        lines = []\n",
        "        for shape in data.get('shapes', []):\n",
        "            label = shape.get('label', '').strip().lower()\n",
        "            if label not in class_map:\n",
        "                # tenta normalizar plurais/acentos manualmente se necess√°rio\n",
        "                continue\n",
        "            cls_id = class_map[label]\n",
        "            xmin, ymin, xmax, ymax = bbox_from_shape(shape)\n",
        "            # converte para YOLO (normalizado)\n",
        "            x_c = ((xmin + xmax) / 2.0) / w\n",
        "            y_c = ((ymin + ymax) / 2.0) / h\n",
        "            ww  = (xmax - xmin) / w\n",
        "            hh  = (ymax - ymin) / h\n",
        "            # clip para [0,1]\n",
        "            x_c = max(0, min(1, x_c)); y_c = max(0, min(1, y_c))\n",
        "            ww  = max(0, min(1, ww));  hh  = max(0, min(1, hh))\n",
        "            lines.append(f\"{cls_id} {x_c:.6f} {y_c:.6f} {ww:.6f} {hh:.6f}\")\n",
        "\n",
        "        with open(label_path, 'w') as lf:\n",
        "            lf.write(\"\\n\".join(lines))\n",
        "\n",
        "        print(\"Convertido:\", json_path.name, \"‚Üí\", label_path.name)\n",
        "\n",
        "# Exemplo de uso:\n",
        "# Ajuste as pastas e se quer mandar para train/val\n",
        "# class_map mapeia os r√≥tulos do LabelMe (em min√∫sculas) para IDs YOLO\n",
        "example_input_folder = \"/content/labelme_jsons\"  #@param {type:\"string\"}\n",
        "send_to_split = \"train\"  #@param [\"train\", \"val\"]\n",
        "images_out = str(IMAGES_TRAIN if send_to_split == \"train\" else IMAGES_VAL)\n",
        "labels_out = str(LABELS_TRAIN if send_to_split == \"train\" else LABELS_VAL)\n",
        "\n",
        "# Mapeie os r√≥tulos do LabelMe para os IDs das classes deste projeto\n",
        "class_map = {\"cachorro\": 0, \"gato\": 1}\n",
        "\n",
        "# Para rodar, descomente a linha abaixo e garanta que `example_input_folder` existe com JSONs + imagens\n",
        "# convert_labelme_folder_to_yolo(example_input_folder, images_out, labels_out, class_map)\n",
        "print(\"Pronto. Ajuste as vari√°veis e descomente a chamada para converter.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "425ca457",
      "metadata": {
        "id": "425ca457"
      },
      "source": [
        "\n",
        "## ü™Ñ (Opcional) Criar split **train/val** automaticamente\n",
        "Se voc√™ tem todas as imagens em uma √∫nica pasta e j√° possui r√≥tulos YOLO correspondentes (`.txt` com mesmo nome),\n",
        "esta c√©lula divide em treino/valida√ß√£o.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "94994b8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94994b8e",
        "outputId": "9bb0c28c-dd7c-498b-aa32-e9b32669b291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defina o bloco para True para rodar a divis√£o.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@title Criar split aleat√≥rio train/val a partir de uma pasta √∫nica { display-mode: \"form\" }\n",
        "import random, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "single_images_dir = \"/content/minhas_imagens\"  #@param {type:\"string\"}\n",
        "single_labels_dir = \"/content/meus_rotulos\"   #@param {type:\"string\"}\n",
        "val_ratio = 0.2                                #@param {type:\"number\"}\n",
        "\n",
        "def move_pair(img_path, dst_img_dir, dst_lbl_dir):\n",
        "    lbl_path = Path(single_labels_dir) / (img_path.stem + \".txt\")\n",
        "    shutil.copy2(img_path, Path(dst_img_dir) / img_path.name)\n",
        "    if lbl_path.exists():\n",
        "        shutil.copy2(lbl_path, Path(dst_lbl_dir) / lbl_path.name)\n",
        "\n",
        "if False:  # Mude para True para executar a divis√£o\n",
        "    imgs = [p for p in Path(single_images_dir).glob(\"*.*\") if p.suffix.lower() in {\".jpg\", \".jpeg\", \".png\"}]\n",
        "    random.shuffle(imgs)\n",
        "    n_val = int(len(imgs) * val_ratio)\n",
        "    val_set = set(imgs[:n_val])\n",
        "    for img in imgs:\n",
        "        if img in val_set:\n",
        "            move_pair(img, IMAGES_VAL, LABELS_VAL)\n",
        "        else:\n",
        "            move_pair(img, IMAGES_TRAIN, LABELS_TRAIN)\n",
        "    print(\"Split conclu√≠do!\")\n",
        "else:\n",
        "    print(\"Defina o bloco para True para rodar a divis√£o.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2a72871",
      "metadata": {
        "id": "f2a72871"
      },
      "source": [
        "\n",
        "## üèãÔ∏è‚Äç‚ôÄÔ∏è Treinar YOLOv8 (transfer learning)\n",
        "- Usa pesos base (`yolov8n.pt`) e treina nas classes `cachorro` e `gato`.\n",
        "- Ajuste `epochs`, `imgsz`, `batch`, `lr0` conforme seu hardware/dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7ee70541",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7ee70541",
        "outputId": "20fe83cc-e9d9-4742-b285-79aa63925a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.203 üöÄ Python-3.12.11 torch-2.8.0+cu126 CPU (AMD EPYC 7B12)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/YOLO_cachorro_gato/datasets/cachorro_gato/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n_cachorro_gato3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/YOLO_cachorro_gato/results, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/YOLO_cachorro_gato/results/yolov8n_cachorro_gato3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "\u001b[34m\u001b[1mtrain: \u001b[0mError loading data from /content/drive/MyDrive/YOLO_cachorro_gato/datasets/cachorro_gato/images/train\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36mget_img_files\u001b[0;34m(self, img_path)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;31m# self.img_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS])  # pathlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mim_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{self.prefix}No images found in {img_path}. {FORMATS_HELP_MSG}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: \u001b[34m\u001b[1mtrain: \u001b[0mNo images found in /content/drive/MyDrive/YOLO_cachorro_gato/datasets/cachorro_gato/images/train. Supported formats are:\nimages: {'pfm', 'tif', 'jpg', 'heic', 'webp', 'tiff', 'bmp', 'jpeg', 'dng', 'png', 'mpo'}\nvideos: {'gif', 'mkv', 'wmv', 'mp4', 'ts', 'm4v', 'avi', 'mpg', 'webm', 'asf', 'mpeg', 'mov'}",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-578048243.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolov8n.pt'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# troque por 'yolov8s.pt'/'m'/'l' se tiver GPU melhor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m results = model.train(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'data.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0;31m# ajuste\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_setup_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# Dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         self.train_loader = self.get_dataloader(\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCAL_RANK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(self, dataset_path, batch_size, rank, mode)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Mode must be 'train' or 'val', not {mode}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# init dataset *.cache only once if DDP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(self, img_path, mode, batch)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \"\"\"\n\u001b[1;32m     79\u001b[0m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munwrap_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_yolo_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mbuild_yolo_dataset\u001b[0;34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m\"\"\"Build and return a YOLO dataset based on configuration parameters.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLOMultiModalDataset\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmulti_modal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mYOLODataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     return dataset(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mimg_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, task, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_segments\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_keypoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Can not use both segments and keypoints.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"channels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcache_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./labels.cache\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction, channels)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_img_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# single_cls and include_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36mget_img_files\u001b[0;34m(self, img_path)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mim_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{self.prefix}No images found in {img_path}. {FORMATS_HELP_MSG}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.prefix}Error loading data from {img_path}\\n{HELP_URL}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfraction\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mim_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_files\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# retain a fraction of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: \u001b[34m\u001b[1mtrain: \u001b[0mError loading data from /content/drive/MyDrive/YOLO_cachorro_gato/datasets/cachorro_gato/images/train\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance."
          ]
        }
      ],
      "source": [
        "\n",
        "#@title Iniciar o treino { display-mode: \"form\" }\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n.pt')  # troque por 'yolov8s.pt'/'m'/'l' se tiver GPU melhor\n",
        "results = model.train(\n",
        "    data=str(DATASET_DIR / 'data.yaml'),\n",
        "    epochs=50,     # ajuste\n",
        "    imgsz=640,     # ajuste\n",
        "    batch=16,      # ajuste\n",
        "    lr0=0.01,      # ajuste\n",
        "    workers=2,     # Colab costuma limitar workers\n",
        "    project=str(RESULTS_DIR),\n",
        "    name='yolov8n_cachorro_gato',\n",
        "    verbose=True\n",
        ")\n",
        "print(\"Treino conclu√≠do. Resultados em:\", RESULTS_DIR / 'yolov8n_cachorro_gato')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oDS4sRmkO8K-"
      },
      "id": "oDS4sRmkO8K-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0ce9b410",
      "metadata": {
        "id": "0ce9b410"
      },
      "source": [
        "\n",
        "## üìä Avalia√ß√£o e m√©tricas\n",
        "Gera **mAP**, **precision**, **recall**, **F1** e matriz de confus√£o.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecc86ea8",
      "metadata": {
        "id": "ecc86ea8"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Valida√ß√£o / M√©tricas { display-mode: \"form\" }\n",
        "val_results = model.val()\n",
        "print(val_results)\n",
        "\n",
        "# Mostrar caminho dos artefatos (curvas, confus√£o, PR, etc.)\n",
        "from pathlib import Path\n",
        "run_dir = Path(RESULTS_DIR) / 'yolov8n_cachorro_gato'\n",
        "print(\"Arquivos de gr√°ficos e m√©tricas (se gerados):\", list(run_dir.glob(\"**/*\"))[:10], \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf8495a4",
      "metadata": {
        "id": "cf8495a4"
      },
      "source": [
        "\n",
        "## üîé Infer√™ncia (previs√µes) em imagens de teste\n",
        "- Coloque algumas imagens em `images/test/` ou aponte `source` para outra pasta (ou v√≠deo).\n",
        "- As imagens com detec√ß√µes ser√£o salvas com bounding boxes na pasta de `predict` da execu√ß√£o.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85f2d493",
      "metadata": {
        "id": "85f2d493"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Rodar previs√µes e salvar sa√≠das { display-mode: \"form\" }\n",
        "pred = model.predict(\n",
        "    source=str(IMAGES_TEST) if any(IMAGES_TEST.iterdir()) else str(IMAGES_VAL),\n",
        "    save=True,\n",
        "    conf=0.25\n",
        ")\n",
        "print(\"Predi√ß√µes salvas em:\", pred[0].save_dir if pred else \"Verifique se h√° imagens de entrada.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dedd2be",
      "metadata": {
        "id": "3dedd2be"
      },
      "source": [
        "\n",
        "## üì¶ Exportar pesos e artefatos\n",
        "Salva pesos finais e zippa a pasta de resultados para download/compartilhamento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8730222b",
      "metadata": {
        "id": "8730222b"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Exportar pesos e compactar resultados { display-mode: \"form\" }\n",
        "best_pt = RESULTS_DIR / 'yolov8n_cachorro_gato' / 'weights' / 'best.pt'\n",
        "last_pt = RESULTS_DIR / 'yolov8n_cachorro_gato' / 'weights' / 'last.pt'\n",
        "print(\"Pesos esperados:\", best_pt, last_pt)\n",
        "\n",
        "# Compactar pasta de resultados\n",
        "import shutil, os\n",
        "zip_out = str(RESULTS_DIR) + \".zip\"\n",
        "if os.path.exists(zip_out):\n",
        "    os.remove(zip_out)\n",
        "shutil.make_archive(str(RESULTS_DIR), 'zip', root_dir=RESULTS_DIR)\n",
        "print(\"ZIP criado em:\", zip_out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e1b7df1",
      "metadata": {
        "id": "3e1b7df1"
      },
      "source": [
        "\n",
        "## üõ†Ô∏è Dicas & Troubleshooting\n",
        "- **Dataset vazio**: confirme que existem imagens e r√≥tulos correspondentes.\n",
        "- **IDs de classe incorretos**: revise o `data.yaml` e os `.txt` (0=cachorro, 1=gato).\n",
        "- **Overfitting**: reduza `epochs`, aumente `val_ratio`, adicione **augmentation** (par√¢metros em `model.train()` ou via Ultralytics settings).\n",
        "- **Baixa mAP em uma classe**: colete mais dados dessa classe, melhore diversidade e rotulagem.\n",
        "- **GPU no Colab**: `Runtime > Change runtime type > T4/A100` (quando dispon√≠vel).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}